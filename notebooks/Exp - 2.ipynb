{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "76e78bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "cohere_api_key = os.environ[\"COHERE_API_KEY\"]\n",
    "huggingface_api_key = os.environ[\"HUGGINGFACEHUB_API_TOKEN\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "28c47111",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import getpass\n",
    "# import os\n",
    "\n",
    "# os.environ[\"COHERE_API_KEY\"] = getpass.getpass(\"Enter your Cohere API key: \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e653dede",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data ingestion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_text_splitters import RecursiveCharacterTextSplitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = TextLoader(\n",
    "    \"C:/Biprayan - 2/LLMops/project/data/demo.txt\",\n",
    "    autodetect_encoding= True\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=200, chunk_overlap=20)\n",
    "docs = text_splitter.split_documents(documents)\n",
    "\n",
    "texts = [doc.page_content for doc in docs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "96501105",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data retrieval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a6001821",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_huggingface import HuggingFaceEndpointEmbeddings\n",
    "\n",
    "\n",
    "embedding_function = HuggingFaceEndpointEmbeddings(\n",
    "    model=\"sentence-transformers/all-MiniLM-L6-v2\",\n",
    "    huggingfacehub_api_token= huggingface_api_key\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "38efd5a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "embedded_docs = embedding_function.embed_documents(texts=texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5e2d4e15",
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_store = FAISS.from_documents(docs, embedding_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cd5d30e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "retrieved_docs = vector_store.similarity_search(\"what is Agentic Document Extraction\", k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4368022c",
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vector_store.as_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2289642c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# promt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "62ac454a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "template=\"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question.\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use ten sentences maximum and keep the answer concise.\n",
    "Question: {question}\n",
    "Context: {context}\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "prompt=ChatPromptTemplate.from_template(template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0338ee67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse ten sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"), additional_kwargs={})])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8ec1769b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.output_parsers import StrOutputParser\n",
    "output_parser = StrOutputParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f6ac4d5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! uv pip install -U langchain-cohere"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "ae4116e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_cohere import ChatCohere\n",
    "\n",
    "llm_model = ChatCohere(\n",
    "    cohere_api_key=cohere_api_key,\n",
    "    model=\"command-a-03-2025\",  # model selection can be changed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2b0307e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='**Agentic Document Extraction** refers to the process of using **agentic AI systems** to extract relevant information, insights, or specific data points from documents in a more intelligent, context-aware, and goal-oriented manner. Unlike traditional document extraction methods (e.g., rule-based systems or simple keyword searches), agentic extraction leverages advanced AI capabilities, such as natural language understanding (NLU), reasoning, and decision-making, to perform tasks more autonomously and adaptively.\\n\\n### Key Characteristics of Agentic Document Extraction:\\n1. **Autonomy**: The system operates with minimal human intervention, identifying and extracting information based on predefined goals or dynamic instructions.\\n2. **Context Awareness**: It understands the context of the document, including nuances, relationships, and implicit meanings, to extract more accurate and relevant data.\\n3. **Goal-Oriented**: The extraction process is driven by specific objectives, such as answering questions, summarizing content, or identifying key entities (e.g., names, dates, locations).\\n4. **Adaptability**: The system can adjust its extraction strategy based on the document type, structure, or complexity, ensuring flexibility across diverse document formats (e.g., PDFs, contracts, invoices, research papers).\\n5. **Interactive Capabilities**: In some cases, agentic systems can interact with users to clarify ambiguities, ask for additional context, or refine extraction results.\\n\\n### Components of Agentic Document Extraction:\\n- **Natural Language Processing (NLP)**: For understanding and interpreting text.\\n- **Machine Learning (ML)**: To improve extraction accuracy over time through training on labeled data.\\n- **Reasoning Engines**: To infer relationships and make logical deductions from the extracted information.\\n- **Knowledge Graphs**: To organize and represent extracted data in a structured, interconnected manner.\\n- **User Interface (UI)**: For presenting results and enabling user interaction if needed.\\n\\n### Applications:\\n- **Legal Document Analysis**: Extracting clauses, obligations, or risks from contracts.\\n- **Financial Reporting**: Pulling key metrics, dates, or entities from financial statements.\\n- **Healthcare**: Extracting patient information, diagnoses, or treatment plans from medical records.\\n- **Research**: Summarizing findings, methodologies, or citations from academic papers.\\n- **Customer Support**: Extracting relevant details from customer emails or support tickets.\\n\\n### Example Workflow:\\n1. **Input**: A user uploads a document (e.g., a contract) and specifies the goal (e.g., \"Extract all termination clauses\").\\n2. **Processing**: The agentic system reads the document, identifies relevant sections, and applies NLP and reasoning to extract the requested information.\\n3. **Output**: The system presents the extracted clauses in a structured format, highlighting key terms and conditions.\\n\\n### Technologies Involved:\\n- **Large Language Models (LLMs)**: For understanding and generating human-like text.\\n- **Optical Character Recognition (OCR)**: For digitizing scanned or image-based documents.\\n- **Entity Recognition (NER)**: For identifying specific types of information (e.g., names, dates).\\n- **Reinforcement Learning**: For optimizing extraction strategies based on feedback.\\n\\nAgentic document extraction represents a significant advancement in AI-driven document processing, enabling more efficient, accurate, and intelligent handling of unstructured data.', additional_kwargs={'id': '73f59bca-2f47-471d-8f44-51053f1fb1b5', 'finish_reason': 'COMPLETE', 'content': '**Agentic Document Extraction** refers to the process of using **agentic AI systems** to extract relevant information, insights, or specific data points from documents in a more intelligent, context-aware, and goal-oriented manner. Unlike traditional document extraction methods (e.g., rule-based systems or simple keyword searches), agentic extraction leverages advanced AI capabilities, such as natural language understanding (NLU), reasoning, and decision-making, to perform tasks more autonomously and adaptively.\\n\\n### Key Characteristics of Agentic Document Extraction:\\n1. **Autonomy**: The system operates with minimal human intervention, identifying and extracting information based on predefined goals or dynamic instructions.\\n2. **Context Awareness**: It understands the context of the document, including nuances, relationships, and implicit meanings, to extract more accurate and relevant data.\\n3. **Goal-Oriented**: The extraction process is driven by specific objectives, such as answering questions, summarizing content, or identifying key entities (e.g., names, dates, locations).\\n4. **Adaptability**: The system can adjust its extraction strategy based on the document type, structure, or complexity, ensuring flexibility across diverse document formats (e.g., PDFs, contracts, invoices, research papers).\\n5. **Interactive Capabilities**: In some cases, agentic systems can interact with users to clarify ambiguities, ask for additional context, or refine extraction results.\\n\\n### Components of Agentic Document Extraction:\\n- **Natural Language Processing (NLP)**: For understanding and interpreting text.\\n- **Machine Learning (ML)**: To improve extraction accuracy over time through training on labeled data.\\n- **Reasoning Engines**: To infer relationships and make logical deductions from the extracted information.\\n- **Knowledge Graphs**: To organize and represent extracted data in a structured, interconnected manner.\\n- **User Interface (UI)**: For presenting results and enabling user interaction if needed.\\n\\n### Applications:\\n- **Legal Document Analysis**: Extracting clauses, obligations, or risks from contracts.\\n- **Financial Reporting**: Pulling key metrics, dates, or entities from financial statements.\\n- **Healthcare**: Extracting patient information, diagnoses, or treatment plans from medical records.\\n- **Research**: Summarizing findings, methodologies, or citations from academic papers.\\n- **Customer Support**: Extracting relevant details from customer emails or support tickets.\\n\\n### Example Workflow:\\n1. **Input**: A user uploads a document (e.g., a contract) and specifies the goal (e.g., \"Extract all termination clauses\").\\n2. **Processing**: The agentic system reads the document, identifies relevant sections, and applies NLP and reasoning to extract the requested information.\\n3. **Output**: The system presents the extracted clauses in a structured format, highlighting key terms and conditions.\\n\\n### Technologies Involved:\\n- **Large Language Models (LLMs)**: For understanding and generating human-like text.\\n- **Optical Character Recognition (OCR)**: For digitizing scanned or image-based documents.\\n- **Entity Recognition (NER)**: For identifying specific types of information (e.g., names, dates).\\n- **Reinforcement Learning**: For optimizing extraction strategies based on feedback.\\n\\nAgentic document extraction represents a significant advancement in AI-driven document processing, enabling more efficient, accurate, and intelligent handling of unstructured data.', 'token_count': {'input_tokens': 501.0, 'output_tokens': 695.0}}, response_metadata={'id': '73f59bca-2f47-471d-8f44-51053f1fb1b5', 'finish_reason': 'COMPLETE', 'content': '**Agentic Document Extraction** refers to the process of using **agentic AI systems** to extract relevant information, insights, or specific data points from documents in a more intelligent, context-aware, and goal-oriented manner. Unlike traditional document extraction methods (e.g., rule-based systems or simple keyword searches), agentic extraction leverages advanced AI capabilities, such as natural language understanding (NLU), reasoning, and decision-making, to perform tasks more autonomously and adaptively.\\n\\n### Key Characteristics of Agentic Document Extraction:\\n1. **Autonomy**: The system operates with minimal human intervention, identifying and extracting information based on predefined goals or dynamic instructions.\\n2. **Context Awareness**: It understands the context of the document, including nuances, relationships, and implicit meanings, to extract more accurate and relevant data.\\n3. **Goal-Oriented**: The extraction process is driven by specific objectives, such as answering questions, summarizing content, or identifying key entities (e.g., names, dates, locations).\\n4. **Adaptability**: The system can adjust its extraction strategy based on the document type, structure, or complexity, ensuring flexibility across diverse document formats (e.g., PDFs, contracts, invoices, research papers).\\n5. **Interactive Capabilities**: In some cases, agentic systems can interact with users to clarify ambiguities, ask for additional context, or refine extraction results.\\n\\n### Components of Agentic Document Extraction:\\n- **Natural Language Processing (NLP)**: For understanding and interpreting text.\\n- **Machine Learning (ML)**: To improve extraction accuracy over time through training on labeled data.\\n- **Reasoning Engines**: To infer relationships and make logical deductions from the extracted information.\\n- **Knowledge Graphs**: To organize and represent extracted data in a structured, interconnected manner.\\n- **User Interface (UI)**: For presenting results and enabling user interaction if needed.\\n\\n### Applications:\\n- **Legal Document Analysis**: Extracting clauses, obligations, or risks from contracts.\\n- **Financial Reporting**: Pulling key metrics, dates, or entities from financial statements.\\n- **Healthcare**: Extracting patient information, diagnoses, or treatment plans from medical records.\\n- **Research**: Summarizing findings, methodologies, or citations from academic papers.\\n- **Customer Support**: Extracting relevant details from customer emails or support tickets.\\n\\n### Example Workflow:\\n1. **Input**: A user uploads a document (e.g., a contract) and specifies the goal (e.g., \"Extract all termination clauses\").\\n2. **Processing**: The agentic system reads the document, identifies relevant sections, and applies NLP and reasoning to extract the requested information.\\n3. **Output**: The system presents the extracted clauses in a structured format, highlighting key terms and conditions.\\n\\n### Technologies Involved:\\n- **Large Language Models (LLMs)**: For understanding and generating human-like text.\\n- **Optical Character Recognition (OCR)**: For digitizing scanned or image-based documents.\\n- **Entity Recognition (NER)**: For identifying specific types of information (e.g., names, dates).\\n- **Reinforcement Learning**: For optimizing extraction strategies based on feedback.\\n\\nAgentic document extraction represents a significant advancement in AI-driven document processing, enabling more efficient, accurate, and intelligent handling of unstructured data.', 'token_count': {'input_tokens': 501.0, 'output_tokens': 695.0}}, id='run--384a5830-ed26-43f4-b0e2-a4f5495d6717-0', usage_metadata={'input_tokens': 501, 'output_tokens': 695, 'total_tokens': 1196})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm_model.invoke(\"what is Agentic Document Extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ceec05b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm_model\n",
    "    | output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "01a91904",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Agentic Document Extraction (ADE) is an advanced system that builds upon traditional Optical Character Recognition (OCR) technology. It utilizes generative AI to go beyond simple text extraction, aiming to truly understand the content of documents. The provided context suggests ADE is a developing field, with early approaches likely to evolve. It highlights the system's ability to move from basic OCR to a more comprehensive understanding of document content. Anirban Chakraborty appears to be a key figure associated with ADE, as they are mentioned as an author and their work is referenced. The context also mentions a diagram illustrating an early ADE approach, indicating a visual representation of the system's functionality. While the exact details of ADE's capabilities are not fully outlined, it is presented as a significant advancement in document processing technology.\""
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"what is Agentic Document Extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "baf23dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "\n",
    "input = {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "\n",
    "chain_2 = (\n",
    "    input | prompt| llm_model| output_parser\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f3a2574d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Agentic Document Extraction (ADE) is an advanced, generative AI-powered system that evolves traditional Optical Character Recognition (OCR) to understand and interpret document content more deeply. It goes beyond simple text extraction to provide meaningful insights and comprehension of the material. ADE represents a significant advancement in document processing technology, leveraging AI to enhance accuracy and utility. The concept is still evolving, with ongoing research addressing key challenges in its development. It aims to bridge the gap between raw text extraction and true content understanding. ADE is discussed in articles by Anirban Chakraborty, highlighting its potential and future directions. The system is designed to improve over time as AI capabilities expand. Its primary goal is to transform how documents are analyzed and utilized in various applications. ADE is a cutting-edge approach to document extraction, promising greater efficiency and intelligence in handling textual data.'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_2.invoke(\"what is Agentic Document Extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a0daa4f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEndpointEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001CF31664050>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse ten sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"), additional_kwargs={})])\n",
       "| ChatCohere(client=<cohere.client.Client object at 0x000001CEF7B5DE80>, async_client=<cohere.client.AsyncClient object at 0x000001CEF7B5FD70>, model='command-a-03-2025', cohere_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "07c8e6ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Agentic Document Extraction (ADE) is an advanced system that evolves traditional Optical Character Recognition (OCR) into a more sophisticated process. It leverages generative AI to go beyond simple text extraction, aiming for a deeper understanding of document content. ADE represents an early approach that is expected to evolve over time. The system addresses key challenges in extracting and interpreting information from documents. It was introduced by Anirban Chakraborty, as mentioned in the provided context. ADE is designed to enhance the capabilities of OCR by incorporating AI-powered understanding. The exact mechanisms and features of ADE are not fully detailed in the given context. However, it is clear that ADE aims to improve document processing by integrating advanced AI techniques. Further specifics about ADE's functionality or applications are not provided in the available information.\""
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data = {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "llm_chain = prompt | llm_model | output_parser\n",
    "\n",
    "final_chain = input_data | llm_chain\n",
    "\n",
    "# Invoke with a plain string so the RunnablePassthrough receives the question text\n",
    "final_chain.invoke(\"what is Agentic Document Extraction\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "231a24a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'context': VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEndpointEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001CF31664050>, search_kwargs={}),\n",
       " 'question': RunnablePassthrough()}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0d40d636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{\n",
       "  context: VectorStoreRetriever(tags=['FAISS', 'HuggingFaceEndpointEmbeddings'], vectorstore=<langchain_community.vectorstores.faiss.FAISS object at 0x000001CF31664050>, search_kwargs={}),\n",
       "  question: RunnablePassthrough()\n",
       "}\n",
       "| ChatPromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context', 'question'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question.\\nIf you don't know the answer, just say that you don't know.\\nUse ten sentences maximum and keep the answer concise.\\nQuestion: {question}\\nContext: {context}\\nAnswer:\\n\"), additional_kwargs={})])\n",
       "| ChatCohere(client=<cohere.client.Client object at 0x000001CEF7B5DE80>, async_client=<cohere.client.AsyncClient object at 0x000001CEF7B5FD70>, model='command-a-03-2025', cohere_api_key=SecretStr('**********'))\n",
       "| StrOutputParser()"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946b3374",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
